{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Load modules from the lib directory\n",
    "sys.path.insert(0, \"../lib\")\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1 = load_resnet(classes=10, shape=(32, 32, 3))\n",
    "cnn_1.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_classifier(cnn: tf.keras.Model) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Build a new model that takes images as input and outputs class probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    `cnn: tf.keras.Model` \n",
    "        The base CNN model to use.\n",
    "\n",
    "    `return`\n",
    "        The new model.\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        cnn,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units = 512),\n",
    "        tf.keras.layers.Dense(units = 10, activation = \"sigmoid\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelCleaner(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, CNN: tf.keras.Model):\n",
    "        super(LabelCleaner, self).__init__()\n",
    "\n",
    "        # Base CNN model\n",
    "        self.CNN = CNN\n",
    "        \n",
    "        # Fully connected dense layers\n",
    "        self.fc_1 = tf.keras.layers.Dense(units = 20, use_bias=False)\n",
    "        self.fc_2 = tf.keras.layers.Dense(units = 512)\n",
    "        self.fc_3 = tf.keras.layers.Dense(units = 512, use_bias=False, activation = \"relu\")\n",
    "        self.fc_4 = tf.keras.layers.Dense(units = 10, use_bias=False,)\n",
    "        \n",
    "        # Batch Normalization layers\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn_3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        img, y = inputs\n",
    "\n",
    "        # Get the CNN output\n",
    "        x = self.CNN(img)\n",
    "\n",
    "        # Embed the output of the CNN to the noisy labels\n",
    "        x = tf.concat([x, y], axis = 1)\n",
    "        \n",
    "        x = self.fc_1(x)    # Linear followed by batch normalization\n",
    "        x = self.bn_1(x)\n",
    "\n",
    "        x = self.fc_2(x)    # Linear followed by batch normalization\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        x = self.fc_3(x)    # ReLU\n",
    "\n",
    "        x = self.fc_4(x)    # Linear followed by batch normalization\n",
    "        x = self.bn_3(x)\n",
    "\n",
    "        x = x + y           # Residual connection\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "resnet50.trainable = False\n",
    "cnn_2 = tf.keras.models.Sequential([\n",
    "    resnet50,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18(10)\n",
    "resnet18.build(input_shape=(None, 32, 32, 3))\n",
    "\n",
    "cnn_3 = tf.keras.models.Sequential([\n",
    "    resnet18,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "n_images: int = 50_000\n",
    "n_noisy: int = 40_000\n",
    "n_clean: int = n_images - n_noisy\n",
    "\n",
    "images : np.ndarray = np.empty((n_images, 32, 32, 3), dtype=np.float32)\n",
    "\n",
    "# Load the data\n",
    "for i in range(n_images):\n",
    "    image_path = f\"../data/images/{i+1:05d}.png\"\n",
    "    images[i,:,:,:] = cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio: float = 0.2\n",
    "train_size: float = n_images - (n_clean * test_ratio)\n",
    "clean_noisy_ratio: float = 1 / 9\n",
    "train_clean_size: int = int(np.floor(train_size * clean_noisy_ratio))\n",
    "val_clean_size: int = int(np.floor((n_clean * (1 - test_ratio)) - train_clean_size))\n",
    "test_clean_size: int = n_clean - train_clean_size - val_clean_size\n",
    "\n",
    "IMG_SIZE: int = 32\n",
    "IMG_SHAPE: tuple = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "BATCH_SIZE: int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_normalized = tf.cast(images, dtype = tf.float32) / 255.0\n",
    "clean_labels_one_hot = tf.one_hot(clean_labels, depth = 10)\n",
    "noisy_labels_one_hot = tf.one_hot(noisy_labels, depth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.data.Dataset.from_tensor_slices((images_normalized, noisy_labels_one_hot))\n",
    "V = tf.data.Dataset.from_tensor_slices((\n",
    "    (images_normalized[:n_clean],\n",
    "    noisy_labels_one_hot[:n_clean]),\n",
    "    clean_labels_one_hot[:n_clean]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = T.shuffle(buffer_size = 1000)\n",
    "T = T.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = V.shuffle(buffer_size = 1000, seed = 42)\n",
    "V_train = V.take(train_clean_size).batch(batch_size = BATCH_SIZE)\n",
    "V_val = V.skip(train_clean_size).take(val_clean_size).batch(batch_size = BATCH_SIZE)\n",
    "V_test = V.skip(train_clean_size + val_clean_size).take(test_clean_size).batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def l1_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = LabelCleaner(cnn_2)\n",
    "cleaner.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    loss = l1_loss,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 20s 98ms/step - loss: 166.3283 - accuracy: 0.1084 - val_loss: 64.9355 - val_accuracy: 0.3022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 17s 102ms/step - loss: 122.4595 - accuracy: 0.1283 - val_loss: 75.8201 - val_accuracy: 0.2808\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 16s 96ms/step - loss: 98.0949 - accuracy: 0.1785 - val_loss: 79.7468 - val_accuracy: 0.2730\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 16s 96ms/step - loss: 79.5864 - accuracy: 0.1716 - val_loss: 58.6266 - val_accuracy: 0.2066\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 15s 93ms/step - loss: 58.9231 - accuracy: 0.1665 - val_loss: 44.1698 - val_accuracy: 0.0975\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 15s 93ms/step - loss: 45.5208 - accuracy: 0.2642 - val_loss: 38.3849 - val_accuracy: 0.1541\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 15s 92ms/step - loss: 41.4802 - accuracy: 0.3516 - val_loss: 36.4909 - val_accuracy: 0.4012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 17s 100ms/step - loss: 41.1384 - accuracy: 0.3701 - val_loss: 35.9234 - val_accuracy: 0.3922\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 16s 99ms/step - loss: 40.1702 - accuracy: 0.3876 - val_loss: 37.1514 - val_accuracy: 0.3862\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 16s 96ms/step - loss: 40.0381 - accuracy: 0.3889 - val_loss: 35.7890 - val_accuracy: 0.4016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f824652760>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner.fit(\n",
    "    V_train,\n",
    "    epochs = 10,\n",
    "    validation_data = V_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 7s 107ms/step - loss: 36.1790 - accuracy: 0.3835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36.179046630859375, 0.38350000977516174]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner.evaluate(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2.trainable = False\n",
    "image_classifier = build_image_classifier(cnn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 69s 174ms/step\n"
     ]
    }
   ],
   "source": [
    "cleaned_labels = cleaner.predict([images, noisy_labels_one_hot], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_cross_entropy(n_verified, n_cleaned):\n",
    "    pi = tf.Variable(tf.ones((n_verified, 10)), dtype = tf.float32)\n",
    "    pj = tf.Variable(tf.ones((n_cleaned, 10)), dtype = tf.float32)\n",
    "\n",
    "    def cross_entropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype = tf.float32)\n",
    "        y_pred = tf.cast(y_pred, dtype = tf.float32)\n",
    "        a = tf.reduce_sum(pi * tf.math.log(y_true), axis = 1)\n",
    "        b = tf.reduce_sum(pj * tf.math.log(y_pred), axis = 1)\n",
    "\n",
    "        loss = -a-b\n",
    "        return loss\n",
    "    return tf.function(cross_entropy)\n",
    "\n",
    "custom_cross_entropy = get_custom_cross_entropy(len(V), len(cleaned_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([inf, inf, inf, inf, inf], dtype=float32)>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_custom_cross_entropy(5, 5)([1,0,0,1,0,0,1,0,0,1], [0,1,0,0,1,1,0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 1., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([1,0,0,1,0,0,1,0,0,1], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier.compile(\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 2.3039 - accuracy: 0.0982\n",
      "Epoch 2/10\n",
      " 388/1563 [======>.......................] - ETA: 1:16 - loss: 2.3036 - accuracy: 0.1016"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [268], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_classifier\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     T,\n\u001b[0;32m      3\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\alixl\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_classifier.fit(\n",
    "    T,\n",
    "    epochs = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b68576675d14688f13df6495c027427b1fa86cc0b514974591414d368704a84c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
