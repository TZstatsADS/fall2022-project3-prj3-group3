{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2kQIyPs4GmX1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Load modules from the lib directory\n",
        "\n",
        "#sys.path.insert(0, \"../lib\")\n",
        "#from resnet import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILDING A MODEL"
      ],
      "metadata": {
        "id": "iWXO6k2UwmdA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P4Z2hqqUGmX2"
      },
      "outputs": [],
      "source": [
        "def build_image_classifier(cnn: tf.keras.Model) -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Build a new model that takes images as input and outputs class probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "\n",
        "    `cnn: tf.keras.Model` \n",
        "        The base CNN model to use.\n",
        "\n",
        "    `return`\n",
        "        The new model.\n",
        "    \"\"\"\n",
        "    return tf.keras.Sequential([\n",
        "        cnn,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units = 512),\n",
        "        tf.keras.layers.Dense(units = 10, activation = \"sigmoid\")\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-lmcAULmGmX3"
      },
      "outputs": [],
      "source": [
        "class LabelCleaner(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, CNN: tf.keras.Model):\n",
        "        super(LabelCleaner, self).__init__()\n",
        "\n",
        "        # Base CNN model\n",
        "        self.CNN = CNN\n",
        "        \n",
        "        # Fully connected dense layers\n",
        "        self.fc_1 = tf.keras.layers.Dense(units = 20, use_bias=False)\n",
        "        self.fc_2 = tf.keras.layers.Dense(units = 512)\n",
        "        self.fc_3 = tf.keras.layers.Dense(units = 512, use_bias=False, activation = \"relu\")\n",
        "        self.fc_4 = tf.keras.layers.Dense(units = 10, use_bias=False,)\n",
        "        \n",
        "        # Batch Normalization layers\n",
        "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn_3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        img, y = inputs\n",
        "\n",
        "        # Get the CNN output\n",
        "        x = self.CNN(img)\n",
        "\n",
        "        # Embed the output of the CNN to the noisy labels\n",
        "        x = tf.concat([x, y], axis = 1)\n",
        "        \n",
        "        x = self.fc_1(x)    # Linear followed by batch normalization\n",
        "        x = self.bn_1(x)\n",
        "\n",
        "        x = self.fc_2(x)    # Linear followed by batch normalization\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        x = self.fc_3(x)    # ReLU\n",
        "\n",
        "        x = self.fc_4(x)    # Linear followed by batch normalization\n",
        "        x = self.bn_3(x) #lets see\n",
        "\n",
        "        x = x + y           # Residual connection\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rc67KdfzGmX4"
      },
      "outputs": [],
      "source": [
        "resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "resnet50.trainable = False\n",
        "cnn_2 = tf.keras.models.Sequential([\n",
        "    resnet50,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units = 10, activation = \"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zVg4Daa44dU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAKE A DATASET"
      ],
      "metadata": {
        "id": "dZrvHWxaw0Of"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaqWlMSEHX_B",
        "outputId": "75c9bb41-9a6a-4697-8601-2bfbf6649093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vdLA6oxrIDLW"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./drive\"):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(\"../data\"):\n",
        "    os.mkdir(\"../data\")\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"./drive/MyDrive/train_data.zip\", 'r') as zip_object:\n",
        "\n",
        "    # Extracting all the members of the zip \n",
        "    # into a specific location.\n",
        "    zip_object.extractall(path=\"../data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l0zEdHRtGmX5"
      },
      "outputs": [],
      "source": [
        "# [DO NOT MODIFY THIS CELL]\n",
        "\n",
        "n_images: int = 50_000\n",
        "n_noisy: int = 40_000\n",
        "n_clean: int = n_images - n_noisy\n",
        "\n",
        "images : np.ndarray = np.empty((n_images, 32, 32, 3), dtype=np.float32)\n",
        "\n",
        "# Load the data\n",
        "for i in range(n_images):\n",
        "    image_path = f\"../data/images/{i+1:05d}.png\"\n",
        "    images[i,:,:,:] = cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# load the labels\n",
        "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
        "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JsdLiIT-GmX5"
      },
      "outputs": [],
      "source": [
        "test_ratio: float = 0.2\n",
        "train_size: float = n_images - (n_clean * test_ratio)\n",
        "clean_noisy_ratio: float = 1 / 9\n",
        "train_clean_size: int = int(np.floor(train_size * clean_noisy_ratio))\n",
        "val_clean_size: int = int(np.floor((n_clean * (1 - test_ratio)) - train_clean_size))\n",
        "test_clean_size: int = n_clean - train_clean_size - val_clean_size\n",
        "\n",
        "IMG_SIZE: int = 32\n",
        "IMG_SHAPE: tuple = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "BATCH_SIZE: int = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qxV2qn8jGmX5"
      },
      "outputs": [],
      "source": [
        "images_normalized = tf.cast(images, dtype = tf.float32) / 255.0\n",
        "clean_labels_one_hot = tf.one_hot(clean_labels, depth = 10)\n",
        "noisy_labels_one_hot = tf.one_hot(noisy_labels, depth = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4xBUBOC_GmX6"
      },
      "outputs": [],
      "source": [
        "T = tf.data.Dataset.from_tensor_slices((images_normalized, noisy_labels_one_hot))\n",
        "V = tf.data.Dataset.from_tensor_slices((\n",
        "    (images_normalized[:n_clean],\n",
        "    noisy_labels_one_hot[:n_clean]),\n",
        "    clean_labels_one_hot[:n_clean]\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WQOq1U-NGmX6"
      },
      "outputs": [],
      "source": [
        "T = T.shuffle(buffer_size = 1000)\n",
        "T = T.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2W9rc8BYGmX6"
      },
      "outputs": [],
      "source": [
        "\n",
        "V = V.shuffle(buffer_size = 1000, seed = 42)\n",
        "V_train = V.take(train_clean_size).batch(batch_size = BATCH_SIZE)\n",
        "V_val = V.skip(train_clean_size).take(val_clean_size).batch(batch_size = BATCH_SIZE)\n",
        "V_test = V.skip(train_clean_size + val_clean_size).take(test_clean_size).batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kind of cleaned dataset\n",
        "cl1 = tf.data.Dataset.from_tensor_slices((\n",
        "    (images_normalized[1000:10000],\n",
        "    noisy_labels_one_hot[1000:10000]),\n",
        "    clean_labels_one_hot[1000:10000]\n",
        "))\n",
        "\n",
        "#cl1=cl1.shuffle(buffer_size=1000)\n",
        "cl1=cl1.shuffle(buffer_size=9000)\n",
        "cl1_train= cl1.take(8100).batch(batch_size = BATCH_SIZE)\n",
        "#.batch(batch_size = BATCH_SIZE)\n",
        "cl1_val= cl1.skip(8100).batch(batch_size = BATCH_SIZE)\n",
        "#.batch(batch_size = BATCH_SIZE)\n",
        "cl1_test= tf.data.Dataset.from_tensor_slices((\n",
        "    (images_normalized[:1000],\n",
        "    noisy_labels_one_hot[:1000]),\n",
        "    clean_labels_one_hot[:1000]\n",
        ")).batch(batch_size = BATCH_SIZE)\n",
        "#.batch(batch_size = BATCH_SIZE)\n",
        "\n",
        "#cl1 = cl1.shuffle(buffer_size = 1000, seed = 42)\n",
        "#cl1_train= cl1.take(8100).batch(batch_size = BATCH_SIZE)\n",
        "#cl1_val = cl1.skip(train_clean_size).take(val_clean_size).batch(batch_size = BATCH_SIZE)\n",
        "\n",
        "#cl1_train = V.take(train_clean_size).batch(batch_size = BATCH_SIZE)\n",
        "#V_val = V.skip(train_clean_size).take(val_clean_size).batch(batch_size = BATCH_SIZE)\n",
        "#V_test = V.skip(train_clean_size + val_clean_size).take(test_clean_size).batch(batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "kz-Ez94A6Eac"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(cl1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW2nlHNk_RuX",
        "outputId": "324b092f-55fc-4860-c81f-4c6ac1449954"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hwavTnxFGmX7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def l1_loss(y_true, y_pred):\n",
        "    return tf.reduce_sum(tf.abs(y_true - y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jdX308GlGmX7"
      },
      "outputs": [],
      "source": [
        "cleaner = LabelCleaner(cnn_2)\n",
        "cleaner.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "    loss = l1_loss,\n",
        "    metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56b4Yi8VGmX7",
        "outputId": "bf7e3e2f-7109-4d5c-c071-8f8aa8d11f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "254/254 [==============================] - 46s 162ms/step - loss: 158.9236 - accuracy: 0.1168 - val_loss: 72.4253 - val_accuracy: 0.2778\n",
            "Epoch 2/30\n",
            "254/254 [==============================] - 42s 167ms/step - loss: 104.2556 - accuracy: 0.1373 - val_loss: 82.4599 - val_accuracy: 0.1867\n",
            "Epoch 3/30\n",
            "254/254 [==============================] - 43s 168ms/step - loss: 72.5850 - accuracy: 0.1400 - val_loss: 50.4256 - val_accuracy: 0.1111\n",
            "Epoch 4/30\n",
            "254/254 [==============================] - 44s 172ms/step - loss: 47.5321 - accuracy: 0.2395 - val_loss: 36.8495 - val_accuracy: 0.1944\n",
            "Epoch 5/30\n",
            "254/254 [==============================] - 42s 167ms/step - loss: 41.6171 - accuracy: 0.3520 - val_loss: 36.7041 - val_accuracy: 0.4267\n",
            "Epoch 6/30\n",
            "254/254 [==============================] - 43s 170ms/step - loss: 40.1767 - accuracy: 0.3846 - val_loss: 36.5409 - val_accuracy: 0.3811\n",
            "Epoch 7/30\n",
            "254/254 [==============================] - 47s 185ms/step - loss: 39.9899 - accuracy: 0.3902 - val_loss: 36.4950 - val_accuracy: 0.3756\n",
            "Epoch 8/30\n",
            "254/254 [==============================] - 48s 188ms/step - loss: 39.0927 - accuracy: 0.3963 - val_loss: 36.0608 - val_accuracy: 0.4033\n",
            "Epoch 9/30\n",
            "254/254 [==============================] - 44s 172ms/step - loss: 39.2192 - accuracy: 0.3973 - val_loss: 35.9745 - val_accuracy: 0.4033\n",
            "Epoch 10/30\n",
            "254/254 [==============================] - 46s 181ms/step - loss: 39.4273 - accuracy: 0.3962 - val_loss: 36.1293 - val_accuracy: 0.4067\n",
            "Epoch 11/30\n",
            "254/254 [==============================] - 46s 180ms/step - loss: 39.1369 - accuracy: 0.3988 - val_loss: 35.8407 - val_accuracy: 0.4156\n",
            "Epoch 12/30\n",
            "254/254 [==============================] - 42s 164ms/step - loss: 39.0118 - accuracy: 0.3988 - val_loss: 37.1638 - val_accuracy: 0.3844\n",
            "Epoch 13/30\n",
            "254/254 [==============================] - 43s 169ms/step - loss: 39.0212 - accuracy: 0.3980 - val_loss: 36.5452 - val_accuracy: 0.4056\n",
            "Epoch 14/30\n",
            "254/254 [==============================] - 44s 175ms/step - loss: 38.9416 - accuracy: 0.3995 - val_loss: 36.1028 - val_accuracy: 0.4222\n",
            "Epoch 15/30\n",
            "254/254 [==============================] - 43s 170ms/step - loss: 38.8464 - accuracy: 0.3995 - val_loss: 36.4545 - val_accuracy: 0.4122\n",
            "Epoch 16/30\n",
            "254/254 [==============================] - 43s 171ms/step - loss: 38.7113 - accuracy: 0.4005 - val_loss: 36.8996 - val_accuracy: 0.4033\n",
            "Epoch 17/30\n",
            "254/254 [==============================] - 46s 181ms/step - loss: 38.6265 - accuracy: 0.3985 - val_loss: 37.3360 - val_accuracy: 0.4000\n",
            "Epoch 18/30\n",
            "254/254 [==============================] - 44s 174ms/step - loss: 38.6462 - accuracy: 0.3975 - val_loss: 36.1644 - val_accuracy: 0.4233\n",
            "Epoch 19/30\n",
            "254/254 [==============================] - 46s 181ms/step - loss: 38.7130 - accuracy: 0.3975 - val_loss: 37.6842 - val_accuracy: 0.3856\n",
            "Epoch 20/30\n",
            "254/254 [==============================] - 43s 169ms/step - loss: 38.6246 - accuracy: 0.4001 - val_loss: 38.7591 - val_accuracy: 0.3733\n",
            "Epoch 21/30\n",
            "254/254 [==============================] - 45s 177ms/step - loss: 38.7828 - accuracy: 0.3969 - val_loss: 37.2395 - val_accuracy: 0.4022\n",
            "CPU times: user 23min 16s, sys: 2min 13s, total: 25min 30s\n",
            "Wall time: 23min 40s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f387d0b2c90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "%%time\n",
        "# cleaner.fit(\n",
        "#     V_train,\n",
        "#     epochs = 30,\n",
        "#     validation_data = V_val\n",
        "# )\n",
        "\n",
        "early_stopping_cl = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "cleaner.fit(cl1_train,epochs = 30,validation_data = cl1_val,callbacks=[early_stopping_cl])\n",
        "    #images[1000:10000], clean_labels[1000:10000] ,#clean_labels[1000:10000],\n",
        "           # validation_split = 0.2,epochs = 30)\n",
        "    #validation_data = V_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p-Vk-E0GmX8",
        "outputId": "4502b400-c189-4824-8148-a4ae95614e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 11s 170ms/step - loss: 37.9426 - accuracy: 0.3895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37.942623138427734, 0.3894999921321869]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "cleaner.evaluate(V_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUIO6MhkGmX8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi6M8kchGmX9",
        "outputId": "6a9dca69-aceb-446b-9632-3e44cb7f3358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 177s 448ms/step\n"
          ]
        }
      ],
      "source": [
        "cleaned_labels_labclean = cleaner.predict([images, noisy_labels_one_hot], batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(clean_labels[:1000],np.argmax(cleaned_labels_labclean , axis=1)[:1000],)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLDpaoGKs8-g",
        "outputId": "ee677064-f592-47c6-c63b-de18902600d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save the trained model as a pickle string.\n",
        "saved_model_labclean = pickle.dumps(cleaner)\n",
        "lab_clean_from_pickle = pickle.loads(saved_model_labclean )\n",
        "  \n",
        "# Use the loaded pickled model to make predictions\n",
        "lab_clean_from_pickle.predict(images_normalized[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "9o5ONrrrQ6la",
        "outputId": "1ecde8c2-1d0d-47f8-f9ed-310241fc2651"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3e2ee9353c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Save the trained model as a pickle string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaved_model_labclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlab_clean_from_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_labclean\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use the loaded pickled model to make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/pickle_utils.py\u001b[0m in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    708\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         raise ValueError(\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0;34mf'Unknown {printable_module_name}: {object_name}. Please ensure '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;34m'this object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;34m'https://www.tensorflow.org/guide/keras/save_and_serialize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown loss function: l1_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING IMAGE CLASSIFIER"
      ],
      "metadata": {
        "id": "FooZ7MrxyhBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ptshCwKHxMyV"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "vgg = VGG16(input_shape=(32,32,3), include_top=False,weights='imagenet')\n",
        "vgg.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "l5oGGXej_BRo"
      },
      "outputs": [],
      "source": [
        "image_classifier2 = build_image_classifier(vgg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KygO_WKf_OIZ"
      },
      "outputs": [],
      "source": [
        "image_classifier2.compile(\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2BxNK1b_XL0",
        "outputId": "27b437da-0301-4290-c703-8563038dc11e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1379/1379 [==============================] - 492s 357ms/step - loss: 2.2166 - accuracy: 0.2229 - val_loss: 2.2531 - val_accuracy: 0.2120\n",
            "Epoch 2/10\n",
            "1379/1379 [==============================] - 495s 359ms/step - loss: 2.2136 - accuracy: 0.2248 - val_loss: 2.2488 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "1379/1379 [==============================] - 491s 356ms/step - loss: 2.2068 - accuracy: 0.2317 - val_loss: 2.2340 - val_accuracy: 0.2129\n",
            "Epoch 4/10\n",
            "1379/1379 [==============================] - 498s 361ms/step - loss: 2.2029 - accuracy: 0.2358 - val_loss: 2.2350 - val_accuracy: 0.2096\n",
            "Epoch 5/10\n",
            "1379/1379 [==============================] - 491s 356ms/step - loss: 2.1999 - accuracy: 0.2309 - val_loss: 2.2394 - val_accuracy: 0.2235\n",
            "Epoch 6/10\n",
            "1379/1379 [==============================] - 482s 350ms/step - loss: 2.1967 - accuracy: 0.2364 - val_loss: 2.2381 - val_accuracy: 0.2147\n",
            "Epoch 7/10\n",
            "1379/1379 [==============================] - 481s 349ms/step - loss: 2.1942 - accuracy: 0.2383 - val_loss: 2.2407 - val_accuracy: 0.2190\n",
            "Epoch 8/10\n",
            " 184/1379 [===>..........................] - ETA: 6:24 - loss: 2.1902 - accuracy: 0.2337"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "image_classifier_model=image_classifier2.fit(images_normalized[1000:],tf.one_hot(np.argmax(cleaned_labels_labclean, axis=1),depth=10 )[1000:],epochs=10,validation_split=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ZsSqrDBn_bKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b538f0d-8a04-461e-e3f0-c1174431f1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 10s 316ms/step\n"
          ]
        }
      ],
      "source": [
        "vgg_pred=image_classifier2.predict(images_normalized[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(clean_labels[:1000],np.argmax(vgg_pred,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58YXqRfNZFKW",
        "outputId": "3500216e-8282-459b-de21-47211ab641d7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.358"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save the trained model as a pickle string.\n",
        "saved_model_VGG = pickle.dumps(vgg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts2App-laXlO",
        "outputId": "f8bdaa28-ff48-4390-e0d9-41570bb9de3f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_from_pickle = pickle.loads(saved_model_VGG)\n",
        "  \n",
        "# Use the loaded pickled model to make predictions\n",
        "vgg_from_pickle.predict(images_normalized[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS5Nvx7RzKDZ",
        "outputId": "82082651-be57-4ec6-c145-0fabe769fe1d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 10s 314ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.1017667 , 0.        , 0.84405017, ..., 0.        ,\n",
              "          0.39529675, 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.9722156 , 0.        , 0.58577245, ..., 0.        ,\n",
              "          0.7981682 , 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.312676  , 0.        , 0.22860822, ..., 0.28974986,\n",
              "          1.1120025 , 0.        ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.57547307, 0.        , 0.        , ..., 0.85850734,\n",
              "          0.3586921 , 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[1.0045614 , 0.        , 0.9415052 , ..., 0.        ,\n",
              "          0.11901689, 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.8553922 , 0.        , 0.2449364 , ..., 0.        ,\n",
              "          0.02795613, 0.        ]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1w_HsVztzdE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b68576675d14688f13df6495c027427b1fa86cc0b514974591414d368704a84c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}